{"cells":[{"cell_type":"markdown","metadata":{"id":"9yQ1TwYgWS0z"},"source":["\n","# Introduction\n","\n","**DESCRIPTION:** In this challenge task I have provided you with skeleton code. There is an image dataset and a text dataset, and you must train deep learning models for them.\n","\n","In these tasks you will be required to write code and write short answer responses to questions in a structured report. You have been provided with a template Word document of this report in which you simply have to fill in the blanks (1-3 sentences is expected).\n","\n","**INSTRUCTIONS:**\n","\n","1.   Copy the skeleton files to your Google Drive.\n","2.   Edit `SKELETON_DIR` in the first cell to point to the skeleton files you uploaded in step 1. The provided code assumes you have uploaded them to \"Telemus/DLTasks\" in your Google Drive.\n","3.   Run the following two cells\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DI_h0wYR8WwZ"},"outputs":[],"source":["!nvidia-smi\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set the working directory for the tasks\n","import os\n","SKELETON_DIR = '/content/drive/MyDrive/TranTasks'\n","os.chdir(SKELETON_DIR)\n","! mkdir -p \"$SKELETON_DIR/saved_models\"\n","! mkdir -p \"$SKELETON_DIR/logs\"\n","\n","# Set up auto-reloading modules from the working directory\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Install extra dependencies\n","!pip install -q transformers==4.27.0\n","!pip install -q wandb==0.15.0\n","!pip install -q torchmetrics==0.11.3\n","\n","\n","# Set the default figure size\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.dpi'] = 120"]},{"cell_type":"markdown","metadata":{"id":"0UMZDfCl9uzf"},"source":["# Task 1 - Image Classification\n","\n","**MARKS**: 66\n","\n","In this first task, you will create a deep learning model to classify images of skin lesions into one of seven classes: \n","\n","1.   \"MEL\" = Melanoma\n","2.   \"NV\" = Melanocytic nevus\n","3.   \"BCC\" = Basal cell carcinoma\n","4.   \"AKIEC\" = Actinic keratosis\n","5.   \"BKL\" = Benign keratosis\n","6.   \"DF\" = Dermatofibroma\n","7.   \"VASC\" = Vascular lesion\n","\n","The data for this task is a subset of: https://challenge2018.isic-archive.com/task3/\n","\n","The data for this task is inside the `data/img` folder. It contains ~3,800 images named like `ISIC_000000.jpg` and the following label files:\n","\n","*   `/data/img/train.csv`\n","*   `/data/img/val.csv`\n","*   `/data/img/train_small.csv`\n","*   `/data/img/val_small.csv`\n","\n","The `small` versions are the first 200 lines of each partition and are included for debugging purposes. To save time, ensure your code runs on the `small` versions first."]},{"cell_type":"markdown","metadata":{"id":"VXe_oJsh2v0R"},"source":["## Task 1a. Explore the training set\n","\n","**INSTRUCTIONS**: Check for data issues. Check the class distribution and at least 1 other potential data issue. Hint: Look in `explore.py` for a function that can plot the class distribution.\n","\n","**REPORT**: What did you check for? What data issues are present in this dataset?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tvZcHWR_nrN_"},"outputs":[],"source":["import pandas as pd\n","\n","IMG_CLASS_NAMES = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n","\n","train_df = pd.read_csv('/content/drive/MyDrive/TranTasks/data/img/train.csv')\n","val_df = pd.read_csv('/content/drive/MyDrive/TranTasks/data/img/val.csv')\n","train_df.head()\n","\n","# count = train_df[IMG_CLASS_NAMES].sum()\n","# print(count)\n","# plt.bar(IMG_CLASS_NAMES, count)\n","\n","# count = val_df[IMG_CLASS_NAMES].sum()\n","# print(count)\n","# plt.bar(IMG_CLASS_NAMES, count)\n","\n","train_df.hist(bins=20, figsize=(15, 10));"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpqxCqPth8va"},"outputs":[],"source":["from PIL import Image\n","# Change the filename to view other examples from the dataset \n","display(Image.open('/content/drive/MyDrive/TranTasks/data/img/ISIC_0024307.jpg'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J6nJ9TKkDM_E"},"outputs":[],"source":["import explore\n","import numpy as np\n","\n","\n","# TODO - Check for data issues\n","# Hint: You can convert from one-hot to integers with argmax\n","#       This way you can convert 1, 0, 0, 0, 0, 0, 0  to class 0 \n","#                                0, 1, 0, 0, 0, 0, 0  to class 1\n","#                                0, 0, 1, 0, 0, 0, 0  to class 2\n","# so it should be something like the following: \n","# train_labels = train_df.values[....].argmax(....)\n","# val_labels = val_df.values[....].argmax(....)\n","#     - you need to fill in the ... parts with the correct values.\n","# You should then print output the contents of train_labels to see if \n","# it matches the contents of train.csv\n","#\n","# Next you can plot the class distributions like the following:\n","# explore.plot_label_distribution(....)\n","#    - do the above for both the train and val labels.\n","#\n","# Following this look for other potential problems with the data\n","#   You can look at practiceTorch1 notebook to see what was checked there.\n","#   You may also think of any other potential problems with the data.\n","\n","print(train_df.dtypes)\n","\n","print(train_df.isnull().sum())\n","\n","# Convert the one-hot encoded labels to integers\n","train_labels = train_df.iloc[:,1:].values.argmax(axis=1)\n","val_labels = val_df.iloc[:,1:].values.argmax(axis=1)\n","\n","# Print out the contents of train_labels\n","print(train_labels)\n","\n","# Print out the contents of val_labels\n","print(val_labels)\n","\n","# Calculate the class counts for the training and validation sets\n","train_counts = train_df[IMG_CLASS_NAMES].sum().values\n","print(train_counts)\n","\n","val_counts = val_df[IMG_CLASS_NAMES].sum().values\n","print(val_counts)\n","\n","# Combine the class counts for both sets\n","total_counts = train_counts + val_counts\n","\n","\n","# Plot the combined class distribution using explore.plot_label_distribution()\n","explore.plot_label_distribution(train_labels, \"Train Class Distribution\", IMG_CLASS_NAMES)\n","explore.plot_label_distribution(val_labels, \"Validation Class Distribution\", IMG_CLASS_NAMES)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EzxriiNQ22CG"},"source":["## Task 1b. Implement Training loop\n","\n","**INSTRUCTIONS**:\n","\n","*   Implement LesionDataset in `datasets.py`. Use the cell below to test your implementation. \n","*   Implement the incomplete functions in `train.py` marked as \"Task 1b\"\n","*   Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code for \"Task 1b\".\n","\n","**REPORT**: Why should you *not use* `random_split` in your code here?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uZTyqK9XvsJ"},"outputs":[],"source":["import datasets\n","\n","ds = datasets.LesionDataset('/content/drive/MyDrive/TranTasks/data/img',\n","                            '/content/drive/MyDrive/TranTasks/data/img/train.csv')\n","input, label = ds[0]\n","print(input)\n","print(label)\n"]},{"cell_type":"markdown","metadata":{"id":"dg_P1_Pd26Bm"},"source":["## Task 1c. Implement a baseline convolutional neural network\n","\n","You will implement a baseline convolutional neural network which you can compare results to. This allows you to evaluate any improvements made by hyperparameter tuning or transfer learning.\n","\n","**INSTRUCTIONS**:\n","\n","*   Implement a `SimpleBNConv` in `models.py` with:\n","    *   5 `nn.Conv2d` layers, with 8, 16, 32, 64, 128 output channels respectively, with the following between each convolution layer:\n","        *   `nn.ReLU()` for the activation function, and\n","        *   `nn.BatchNorm2d`, and\n","        *   finally a `nn.MaxPool2d` to downsample by a factor of 2.\n","*   Use a normalised confusion matrix on the model's validation predictions in `train.py`.\n","*  Go to the [Model Training Cell](#task-1-model-training) at the end of Task 1 and fill in the required code to train the model.\n","\n","Training should take about 1 minute/epoch. Validation accuracy should be 60-70%, but UAR should be around 20-40%.\n","\n","**REPORT**: As training sets get larger, the length of time per epoch also gets larger. Some datasets take over an hour per epoch. This makes it impractical to debug typos in your code since it can take hours after starting for the program to reach new code. Name two ways to significantly reduce how long each epoch takes - for debugging purposes - while still using real data and using the real training code.\n","\n","**REPORT**: Show the confusion matrix and plots of the validation accuracy and UAR in your report, and explain what is going wrong. \n","(Right-click a plot and select \"save image as...\" to save the image to your computer)"]},{"cell_type":"markdown","metadata":{"id":"bnlbHlO953Dw"},"source":["## Task 1d. Account for data issues\n","\n","**INSTRUCTIONS**: Account for the data issues in Task 1a and retrain your model.\n","\n","**REPORT**: How did you account for the data issues? Was it effective? How can you tell? Show another confusion matrix."]},{"cell_type":"markdown","metadata":{"id":"z4bd8vMQ3C6b"},"source":["## Task 1e. Data Augmentation\n","\n","**INSTRUCTIONS**: \n","\n","*   Add an `augment` flag to LesionDataset which specifies whether any augmentation is done to the images. Ensure it is set to `True` *only* for the training dataset.\n","*   Use random horizontal flips\n","*   Use at least 2 other different non-deterministic augmentations\n","\n","**REPORT:** Are random vertical flips appropriate for this dataset? Why?\n","\n","Using data augmentation does not guarantee improved model performance. Data augmentation can hurt test performance by making the model train on unrealistic images.\n","\n","**REPORT**: What effect did Data Augmentation have on performance? Show a screenshot of the relevant graphs from Weights & Biases for evidence.\n","\n","**CHALLENGE**: Apply 5 crop augmentation with crop size 200x300. Make a distinct model which uses 5 crops at once to give a single answer. Include in your report how you did this and report the effect on performance."]},{"cell_type":"markdown","metadata":{"id":"3DkP5Mg48Gm1"},"source":["## Task 1f. Chase improved performance\n","\n","**INSTRUCTIONS**: \n","*   Create a model from a pre-trained model from the torchvision model zoo. We recommend Resnet18, but you may use any model you like. You may freeze the weights of all layers except the last, or fine-tune all the weights. https://cloudstor.aarnet.edu.au/plus/s/TsYJXyJWch0h7TD\n","*   Create your own models, modifying the model architecture, try different losses, learning rates. Change anything you like except the evaluation metrics in search of a better model.\n","\n","Train at least 10 different models, each with a different combination.\n","\n","**REPORT**: Create a table in an excel spreadsheet to record your results. Make sure it includes every parameter of variation between your combinations as a separate column. Include notes about what you were thinking/hoping for each combination as a number column in the spreadsheet.\n","\n","In addition to the excel spreadsheet generate a report using Weights and Biases of the models you trained and the performance curves. Save the report as a pdf and include this in your submission. Please see this link on how to generate reports with Weights and Biases. https://docs.wandb.ai/guides/reports\n","\n","Play around with Weights and Biases to see what cool features you can dig out and use to better visualize the training results and use that to improve the information shared via the report. \n","\n","Write a discussion about the key findings from the experimental results.\n","\n","**CHALLENGE REPORT**: Assuming you use the full dataset in a single epoch, if you halve the size of the batch size, what happens to the number of times that you update the weights per epoch? With reference to the gradients, under what circumstances is this good?"]},{"cell_type":"markdown","metadata":{"id":"RxhIzDQjt4mu"},"source":["<a name=\"task-1-model-training\"></a>\n","## Model Training Cell\n","\n","Note we will be using Weights and Biases to keep track of our experimental runs and evaluation metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tFG3cT2i53Q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from torch.autograd import Variable\n","import datasets\n","import models\n","import train\n","from train import device\n","from train import plot_confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","\n","torch.cuda.empty_cache()\n","!nvidia-smi\n","\n","torch.manual_seed(42)\n","\n","NUM_EPOCHS = 2\n","BATCH_SIZE = 64\n","\n","NUM_CLASSES = len(IMG_CLASS_NAMES)\n","\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","    torch.cuda.set_device(device)\n","\n","print(device)\n","\n","# model = models.SimpleBNConv(device) \n","model = models.SimpleBNConv(num_classes=NUM_CLASSES)\n","\n","print(model)\n","\n","model = model.to(device)\n","\n","\n","\n","# Create datasets/loaders\n","# TODO Task 1b - Create the data loaders from LesionDatasets\n","# TODO Task 1d - Account for data issues, if applicable\n","\n","train_dataset = datasets.LesionDataset('/content/drive/MyDrive/TranTasks/data/img',\n","                            '/content/drive/MyDrive/TranTasks/data/img/train.csv', augment = True)\n","val_dataset = datasets.LesionDataset('/content/drive/MyDrive/TranTasks/data/img',\n","                            '/content/drive/MyDrive/TranTasks/data/img/val.csv', augment = False)\n","\n","width, height = train_dataset.get_image_size(0)\n","print(f'{width}x{height}')\n","\n","width, height = val_dataset.get_image_size(0)\n","print(f'{width}x{height}')\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# TODO Task 1d - Account for data issues, if applicable\n","# defining the Optimizer \n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train model\n","# TODO Task 1c: Set to ident_str to a string that identifies this particular\n","#               training run. Note this line in the training code\n","#                     exp_name = f\"{model.__class__.__name__}_{ident_str}\"\n","#               So it means the the model class name is already included in the\n","#               exp_name string. You can consider adding other information particular\n","#               to this training run, e.g. learning rate (lr) used, \n","#               augmentation (aug) used or not, etc.\n","\n","train.train_model(model, train_loader, val_loader, optimizer, criterion,\n","                  IMG_CLASS_NAMES, NUM_EPOCHS, project_name = \"CSE5DL Assignment Task 1\",\n","                  ident_str= \"TranTasks\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nHmk8S-B3PkF"},"source":["# Task 2 - News article classification\n","\n","You will first create your own model to classify news articles into one of the following classes:\n","\n","*   World\n","*   Sport\n","*   Business\n","*   Sci/Tech\n","\n","You will then compare it to a pre-trained DistilBERT model that has been fine-tuned, similar to Lab 6. Note: using a model pre-trained on a source task for a new target task is called \"transfer learning\" whether you fine-tune it or not.\n","\n","The data for this task is a subset of: https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv"]},{"cell_type":"markdown","metadata":{"id":"DThd7TE73SVK"},"source":["## Task 2a. Exploring the dataset\n","\n","**INSTRUCTIONS**: Check for at least 2 data issues.\n","\n","**REPORT**: What did you check for? What data issues exist, if any? Report anything you checked even if it turned out the data did not have that issue. We want to know what you are checking."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJdQupWVOuOw"},"outputs":[],"source":["import pandas as pd\n","\n","with open('/content/drive/MyDrive/TranTasks/data/txt/classes.txt') as f:\n","    TXT_CLASS_NAMES = [line.rstrip('\\n') for line in f]\n","\n","train_df = pd.read_csv('/content/drive/MyDrive/TranTasks/data/txt/train.csv', header=None)\n","val_df = pd.read_csv('/content/drive/MyDrive/TranTasks/data/txt/val.csv', header=None)\n","train_df.head()\n","val_df.head()\n","\n","print(TXT_CLASS_NAMES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ULAXaX9F1SJ"},"outputs":[],"source":["import explore\n","# TODO Check for data issues.\n","# Again you should fill in the following:\n","# train_labels = ...\n","# val_labels = ....\n","#   - Note the csv file has class labels start from 1 but\n","#     pytorch expects class labels to start from 0 instead. \n","#\n","# explore.plot_label_distribution(....) for train labels\n","# explore.plot_label_distribution(....) for val labels\n","# \n","# check for other kinds of problems with the data like you did for Task 1a.\n","# View the first few rows of the dataframes\n","\n","print(train_df.head())\n","print(val_df.head())\n","\n","# Print classes\n","print(TXT_CLASS_NAMES)\n","\n","# Check data types and null values\n","print(train_df.dtypes)\n","print(train_df.isnull().sum())\n","print(val_df.dtypes)\n","print(val_df.isnull().sum())\n","\n","# Subtract 1 from labels to make them start from 0, as PyTorch expects\n","train_labels = train_df[0] - 1\n","val_labels = val_df[0] - 1\n","\n","# Check distributions of labels\n","explore.plot_label_distribution(train_labels, \"Train Class Distribution\", TXT_CLASS_NAMES)\n","explore.plot_label_distribution(val_labels, \"Validation Class Distribution\", TXT_CLASS_NAMES)\n","\n","# Check for class imbalance\n","train_counts = np.bincount(train_labels)\n","val_counts = np.bincount(val_labels)\n","print(\"Training set class counts:\", train_counts)\n","print(\"Validation set class counts:\", val_counts)\n","\n","# Check if there are any other potential problems with the data\n","# Here we check if there are any classes in the validation set that do not appear in the training set\n","missing_classes = set(val_labels) - set(train_labels)\n","if missing_classes:\n","    print(\"Warning: The following classes appear in the validation set but not in the training set:\", missing_classes)\n"]},{"cell_type":"markdown","metadata":{"id":"AiR4YMsC3WTf"},"source":["## Task 2b. Clustering and visualising embeddings from a pre-trained model\n","\n","**INSTRUCTIONS**: \n","\n","*  Implement the `TextDataset` class in the `datasets.py` file. Consider adding a small code block to test your implementation, as provided in task 1b.\n","\n","*   Complete `visualise_embeddings.py` and run it. Make sure you instantiate two different models to visualize. One is the sequence classification model and the other is the token classification model. For the sequence classification model the code will visualize the CLS token. For the token classification model the model will perform average pool over all output tokens except the CLS token output.\n","\n","* The `visualise_embeddings.py` file does the following:\n","    *   visualise embeddings of the news articles from the two pre-trained `'distilbert-base-uncased'` model (i.e. the models which have not yet been fine-tuned on the labels) using T-SNE. T-SNE is a popular dimensionality reduction method that takes data from a high dimensional space and reduces it to just two dimensions while trying to preserve the right distances between points. The visualization will represent each article by a point with a color corresponding to their true label. Ideally the colors are well separated into separate clusters. If this happens it will be really cool since it means we did not even need to fine-tune the model on our data, it is already able to separate the classes.\n","    *   Next the code will run K-Means clustering on the validation set to group the data into separate clusters. The code will then colour the points based on which cluster they belong to rather than the ground truth label. \n","\n","\n","**REPORT**: By looking at the resulting images of the two models (sequence classification and token classification), which two classes have the most similar embeddings? How can you tell? Did you expect this, if so, why, if not why not?\n","\n","**CHALLENGE**: Only attempt this after completing the rest of Task 2.\n","\n","*   Modify `visualise_embeddings.py` so that it can load the weights for a fine-tuned DistilBERT model. Then visualize the data points with their corresponding true labels. \n","*   Next instead of using K-Means for the second visualisation, use the model's own predicted labels to colour the points.\n","\n","Present the resulting images in your report."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2yOEBQcF2yO"},"outputs":[],"source":["import visualise_embeddings\n","SENTENCE_LEN = 80\n","# Run this code to visualize the results from embedding text using the sequence classification model\n","visualise_embeddings.mk_plots(SENTENCE_LEN, sequenceClassificationModel = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfw82WIyWckq"},"outputs":[],"source":["import visualise_embeddings\n","SENTENCE_LEN = 80\n","# Run this code to visualize the results from embedding text using the token classification model\n","visualise_embeddings.mk_plots(SENTENCE_LEN, sequenceClassificationModel = False)"]},{"cell_type":"markdown","metadata":{"id":"aGx4lFbx3bS5"},"source":["## Task 2c. Models\n","\n","**INSTRUCTIONS**:\n","\n","*   Complete `TextMLP` in `models.py`. It should be a simple MLP with 8 Linear layers. It should first embed the inputs into a vocabulary of size 30522. Use an output feature size of 256 in all hidden layers and a feature size of 128 for the embeddings. Flatten the sentence after embedding, but before it goes into any Linear layers. Use batch norm and ReLU. Train for 1000 epochs with learning rate of 0.001 and a batch size of 512.\n","*   Complete `DistilBertForClassification` in `models.py`. This model should replace the last layer with an `nn.Linear` with 4 outputs for classification. Hint: Call `print()` on the DistilBERT model to observe the layers and their names before attempting this. Train for 4 epochs with learning rate of 0.001 and a batch size of 64.\n","\n","Each of these should take around 10 minutes to complete.\n","\n","Go to the [Model Training Cell](#task-2-model-training) at the end of Task 2 and fill in the required code to train the model.\n","\n","**REPORT**: The saved model weights of a fine-tuned DistilBERT model are >200MB, but you only created one small `nn.Linear` layer. Why is the saved model so large? \n","\n","**REPORT**: These models should accept only input with a dtype of `torch.int64`. What do each of these longs (`int64`) represent?"]},{"cell_type":"markdown","metadata":{"id":"IRhQjiDtQbFM"},"source":["## Task 2d. Learning Rate\n","\n","Fine-tuning `DistilBertForSequenceClassification` with Adam at a learning rate of 0.001 results in very poor accuracy (~26%).\n","\n","**INSTRUCTIONS**: \n","\n","*   Uncomment the lines marked `Task 2d` in `train.py`\n","*   Execute the below cell to begin training and observe the class distribution per batch\n","*   Comment the lines marked `Task 2d` in `train.py` so they no longer interfere with the training.\n","\n","\n","**REPORT**: What is wrong with the class distributions? The learning rate can be changed to fix it. Should you increase or decrease the learning rate? How can you tell?\n","\n","**REPORT**: After fixing the learning rate, comment on the relative train/val performance between these two models. Which model performed better on each partition? Is this expected? If so, why?\n","\n","When you have finished Task 2d. Go back to Task 2b and finish the challenge if you are up to it. You should get a pleasant surprise if you have done everything correctly.\n"]},{"cell_type":"markdown","metadata":{"id":"jkIB_B2t_yps"},"source":["<a name=\"task-2-model-training\"></a>\n","## Model Training Cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sb3PAZIGF35d"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","import datasets\n","import models\n","import train\n","\n","torch.manual_seed(42)\n","\n","SENTENCE_LEN = 80\n","NUM_EPOCHS = 4\n","BATCH_SIZE = 64\n","\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","    torch.cuda.set_device(device)\n","\n","print(device)\n","\n","model = models.DistilBertForClassification(n_classes=4)\n","model = model.to(device)\n","\n","print(model)\n","\n","# Create datasets/loaders\n","# TODO: Create the data loaders from TextDatasets\n","# train_dataset = ...\n","# val_dataset = ...\n","# train_loader = ...\n","# val_loader = ...\n","\n","train_dataset = datasets.TextDataset(fname='/content/drive/MyDrive/TranTasks/data/txt/train.csv', sentence_len=SENTENCE_LEN)\n","val_dataset = datasets.TextDataset(fname='/content/drive/MyDrive/TranTasks/data/txt/val.csv', sentence_len=SENTENCE_LEN)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n","\n","\n","\n","# Instantiate model, optimizer and criterion\n","# TODO: Make an instance of your model\n","# model = models.<**put the name of the model class you created in the model file here**>\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# TODO Change ident_str to something that identifying this experiment e.g. lr0001\n","# Train model. We are using the same train model function we wrote for task 1.\n","train.train_model(model, train_loader, val_loader, optimizer, criterion,\n","                  TXT_CLASS_NAMES, NUM_EPOCHS, project_name = \"CSE5DL Assignment Task 2\",\n","                  ident_str='**TranTasks**')"]},{"cell_type":"markdown","metadata":{"id":"bo9kWUc1ga2_"},"source":["# Super challenge task\n","\n","This challenge task is quite difficult and will really test your mastery of PyTorch and `nn.Linear` layers.\n","\n","We can manually assign weights to an `nn.Linear` like this:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNSRGuIFhPD8"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","lin = nn.Linear(10, 20)\n","manual_weights = torch.arange(20*10).reshape(lin.weight.shape)\n","lin.weight.data[:] = manual_weights\n","lin.bias.data[:] = 0"]},{"cell_type":"markdown","metadata":{"id":"IY8ecPzVhqeL"},"source":["But this does not calculate anything useful. A Linear layer simply performs a weighted sum (plus bias). We can choose weights/biases to perform known operations.\n","\n","**INSTRUCTIONS**: \n","1.   Given an `nn.Linear(1, 1)` layer, set the weights such that the layer adds 1 to it's input.\n","2.   Given an `nn.Linear(1, 1)` layer, set the weights such that the layer calculates `y = 3x + 2`.\n","3.   Given an `nn.Linear(4, 1)` layer, set the weights such that the layer calculates the average of it's inputs.\n","4.   Given an `nn.Linear(4, 2)` layer, set the weights such that the layer calculates both the average of it's inputs and the sum of the inputs.\n","5.   Given an `nn.Linear(3, 3)` layer, set the weights such that the layer returns the inputs, but in reverse order.\n","6.   Given an `nn.Linear(5, 2)` layer, set the weights such that the layer always returns `(4,2)`\n","\n","\n","Note: We would never use this in a deep learning model; this challenge is to prove that you understand the mathematics and coding mechanics of the `nn.Linear` layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"py6eOCV4hp8z"},"outputs":[],"source":["import sc1\n","sc1.test_1(sc1.modify_lin_1)\n","sc1.test_2(sc1.modify_lin_2)\n","sc1.test_3(sc1.modify_lin_3)\n","sc1.test_4(sc1.modify_lin_4)\n","sc1.test_5(sc1.modify_lin_5)\n","sc1.test_6(sc1.modify_lin_6)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"private_outputs":true,"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}